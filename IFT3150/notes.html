<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="keywords" content="HTML, CSS">
  <meta name="description" content="Project for the IFT 3150 course at the
	 University of Montreal">
  <title>IFT 3150 - Project in Computer Science</title>
  <link rel="stylesheet" href="style_ift3150.css">
</head>

<body style="padding: 30px 10vw; background-color:skyblue;">

<h1 class="title">
  Notes and References
</h1>

<!-- Q&A -->
<h2>Q&A and Tutorials</h2>
<li><a href="https://docs.google.com/document/d/1vOtb7bz6TroRpUP5-nYWrTpOrVu6BRv0/edit">
  Questions and Answers
</a></li>
<i>Notes taken from meetings and weekly tutorials.</i>
<hr class="style">

<!-- READINGS -->
<h2>Readings</h2>
<li><a href="pdf_files/Reading Notes.pdf">Reading Notes</a></li>
<i>This document contains notes related to: <br>
  - Explanation of Q-learning and DQN. <br>
  - Recap of supervised learning and reinforcement learning. <br>
  - Papers related to generalization in RL</i>

<p> Papers about DQN: <br>
  1. <a href="https://arxiv.org/abs/1908.04127">
    A review on Deep Reinforcement Learning for Fluid Mechanics</a><br>
  2. <a href="https://arxiv.org/abs/1312.5602">
    Playing Atari with Deep Reinforcement Learning</a><br>
</p>

<p> Papers about Generalization: <br>
  1. <a href="https://www.linkedin.com/pulse/anymorph-learning-transferable-policies-inferring-agent-trabucco/">
    Morphology-Agnostic Learning</a><br>
  2. <a href="https://arxiv.org/abs/2111.09794">
    A Survey of Generalisation in Deep Reinforcement Learning</a>
  [<b>Zero-shot Transfer only</b>]<br>
  3. <a href="https://arxiv.org/abs/2111.09794">
    Multi-Task Reinforcement Learning with Soft Modulatization</a> [reading] <br>
  4. <a href="https://arxiv.org/abs/2111.09794">
    Diversity is All You Need: Learning Skills without a Reward Function</a> [reading] <br>
</p>

<hr class="style">

<!-- RLKIT -->
<h2>RLKIT</h2>
<li><a href="https://docs.google.com/document/d/1vIDhLqd3ToPqBElg3An7qv5xh9Mq5awW/edit">Learning RLKIT</a></li>
<i>Explore different deep RL algorithms with the rlkit package. Currently, I'm testing out
  one of the examples shown in the github link, which is the DQN Algorithm with Cartpole.</i>
<p>Reference: <br><a href="https://github.com/rail-berkeley/rlkit">RLKIT package</a></li></p>
<hr class="style">

<!-- FUNDAMENTALS OF RL -->
<h2>Fundamentals of RL</h2>
<li><a href="pdf_files/RL Summary.pdf">RL Summary</a></li><br>
<li><a href="pdf_files/RL Notes.pdf">RL Notes</a></li><br>
<li><a href="https://docs.google.com/document/d/1BbG7_bmiCyOxntJSl_R_z2tQaAZ2AG7T/edit">First Implementation in RL</a></li>
<i>Tutorial about stable-baselines3, OpenAI spaces, and other tools for analyzing RL problems.</i>

<p>References:<br>
<i>Theory of RL:</i><br>
  <a href="https://www.youtube.com/watch?v=i7q8bISGwMQ&list=PLMrJAkhIeNNQe1JXNvaFvURxGY4gE9k74&index=2">
    Lectures of Steven L. Brunton</a><br>
  <a href="https://faculty.washington.edu/sbrunton/databookRL.pdf">
    RL Textbook [Data Driven Science & Engineering]</a><br>
  Glen's Robot Learning Lectures (IFT 6163)
</p>

<p>
  <i>Practise of RL:</i><br>
  <a href="https://www.youtube.com/watch?v=Mut_u40Sqz4">
    Reinforcement Learning for Beginners (3 small projects) with OpenAI</a>
</p>
<hr class="style">

<!-- DOCUMENTS FOR PROJECTS -->
<h2>Other Documents for the Project</h2>
<li><a href="https://docs.google.com/document/d/1Ciug_FlkTgXTZYKA6cHVKw6rtQq4friL/edit">
  Title and Abstract</a></li>

</body>
</html>